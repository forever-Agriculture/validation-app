# ðŸ¦„ Unicorn Nest ðŸ¦„
## Candidate Test Assessment

## 1. Story

We extract structured data on venture investments from the web using Language Models.

Artifacts of the early pipeline steps contain not only the extracted structural data, but also the pseudo-citations proving each extracted value.

Prefix pseudo- is used here, to highlight the fact that so-called "citations" are obtained from language models inference, therefore there is no strict correspondence of the text fragments to the source and moreover, "citations" may be hallucinated and irrelevant.

Along with each extracted value, we also store a citation from the website that is supposed to support the information.

### Data Sample:

```json
"name": {
   "value": "KCRise Fund",
   "citation": "KCRise Fund is a venture capital firm focused on investing in early-stage technology companies with a strategic connection to the Kansas City region."
}
```
We would like to automate the validation at the next pipeline stage in order to optimize human workload on manual reviews.

## 2. Task

Propose and implement the validation stage indicating the likelihood of the extracted value being true based on the similarity of the attached citation to the relevant fragment of the text source.
Use that to classify the extracted values as "likely true" or "likely untrue", meaning that manual data review is mandatory for the data sample.
In case of difficulties with solution design, use the following approach as a baseline:

Apply the Levenshtein distance algorithm. A citation is considered valid if the Levenshtein distance between the citation and the most similar substring within the source text does not exceed min(2, 10% of the citation's length). Also consider minimalistic text normalisation before applying the Levenshtein distance.


## 3. Input Data Format (data.json)
The input to the validation pipeline is a JSON file containing structured extracted data for each investor, along with raw text from the source website. Each entry in the file is a JSON object with the following fields:

**name** â€” extracted name of the investment fund or investor.

**investor_type** â€” extracted type of the investor (e.g., VC, Angel, CVC).

**fund_main_location** â€” extracted headquarters location.

**investment_stages_and_rounds** â€” extracted list or description of investment stages and funding rounds the investor focuses on (e.g., Seed, Series A).

**source_website_text** â€” the full raw text content scraped from the fundâ€™s official website, used as the reference for validation of extracted values.

Each extracted field (like name, fund_main_location, etc.) is itself an object containing:

**value** â€” the structured value inferred by the model.

**citation** â€” the pseudo-citation generated by the model to justify the value.

## 4. Requirements

- **Language:** Python 3.13
- **Distribution:** public Github repository

### Project structure:

- **README.MD** documenting the solution:
  - Brief explanation of the used approach
  - Instructions for Running Locally
  - Analysis of the algorithm's business performance